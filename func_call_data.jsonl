{"abstract":"  Bayesian network is a complete model for the variables and their\nrelationships, it can be used to answer probabilistic queries about them. A\nBayesian network can thus be considered a mechanism for automatically applying\nBayes' theorem to complex problems. In the application of Bayesian networks,\nmost of the work is related to probabilistic inferences. Any variable updating\nin any node of Bayesian networks might result in the evidence propagation\nacross the Bayesian networks. This paper sums up various inference techniques\nin Bayesian networks and provide guidance for the algorithm calculation in\nprobabilistic inference in Bayesian networks.\n","id":"http:\/\/arxiv.org\/abs\/1011.0935v2","metadata":{"abstract":"  Bayesian network is a complete model for the variables and their\nrelationships, it can be used to answer probabilistic queries about them. A\nBayesian network can thus be considered a mechanism for automatically applying\nBayes' theorem to complex problems. In the application of Bayesian networks,\nmost of the work is related to probabilistic inferences. Any variable updating\nin any node of Bayesian networks might result in the evidence propagation\nacross the Bayesian networks. This paper sums up various inference techniques\nin Bayesian networks and provide guidance for the algorithm calculation in\nprobabilistic inference in Bayesian networks.\n","authors":["Jianguo Ding"],"categories":["cs.AI","cs.NI"],"comment":"14 pages, 9 figures, book chapter","id":"http:\/\/arxiv.org\/abs\/1011.0935v2","primary_category":"cs.AI","pubdate":"2010-11-03T16:50:22Z","title":"Probabilistic Inferences in Bayesian Networks"}}
{"abstract":"  Bayesian networks are basic graphical models, used widely both in statistics\nand artificial intelligence. These statistical models of conditional\nindependence structure are described by acyclic directed graphs whose nodes\ncorrespond to (random) variables in consideration. A quite important topic is\nthe learning of Bayesian network structures, which is determining the best\nfitting statistical model on the basis of given data. Although there are\nlearning methods based on statistical conditional independence tests,\ncontemporary methods are mainly based on maximization of a suitable quality\ncriterion that evaluates how good the graph explains the occurrence of the\nobserved data. This leads to a nonlinear combinatorial optimization problem\nthat is in general NP-hard to solve. In this paper we deal with the complexity\nof learning restricted Bayesian network structures, that is, we wish to find\nnetwork structures of highest score within a given subset of all possible\nnetwork structures. For this, we introduce a new unique algebraic\nrepresentative for these structures, called the characteristic imset. We show\nthat these imsets are always 0-1-vectors and that they have many nice\nproperties that allow us to simplify long proofs for some known results and to\neasily establish new complexity results for learning restricted Bayes network\nstructures.\n","id":"http:\/\/arxiv.org\/abs\/1011.6664v1","metadata":{"abstract":"  Bayesian networks are basic graphical models, used widely both in statistics\nand artificial intelligence. These statistical models of conditional\nindependence structure are described by acyclic directed graphs whose nodes\ncorrespond to (random) variables in consideration. A quite important topic is\nthe learning of Bayesian network structures, which is determining the best\nfitting statistical model on the basis of given data. Although there are\nlearning methods based on statistical conditional independence tests,\ncontemporary methods are mainly based on maximization of a suitable quality\ncriterion that evaluates how good the graph explains the occurrence of the\nobserved data. This leads to a nonlinear combinatorial optimization problem\nthat is in general NP-hard to solve. In this paper we deal with the complexity\nof learning restricted Bayesian network structures, that is, we wish to find\nnetwork structures of highest score within a given subset of all possible\nnetwork structures. For this, we introduce a new unique algebraic\nrepresentative for these structures, called the characteristic imset. We show\nthat these imsets are always 0-1-vectors and that they have many nice\nproperties that allow us to simplify long proofs for some known results and to\neasily establish new complexity results for learning restricted Bayes network\nstructures.\n","authors":["Raymond Hemmecke","Silvia Lindner","Milan Studený"],"categories":["math.OC","cs.DS","cs.IT","math.IT","62F15, 68T05, 90C05, 90C09, 90C10, 9090C27, 90C60,"],"comment":"","id":"http:\/\/arxiv.org\/abs\/1011.6664v1","primary_category":"math.OC","pubdate":"2010-11-30T20:20:55Z","title":"Learning restricted Bayesian network structures"}}
{"abstract":"  Bayesian networks are directed acyclic graphs representing independence\nrelationships among a set of random variables. A random variable can be\nregarded as a set of exhaustive and mutually exclusive propositions. We argue\nthat there are several drawbacks resulting from the propositional nature and\nacyclic structure of Bayesian networks. To remedy these shortcomings, we\npropose a probabilistic network where nodes represent unary predicates and\nwhich may contain directed cycles. The proposed representation allows us to\nrepresent domain knowledge in a single static network even though we cannot\ndetermine the instantiations of the predicates before hand. The ability to deal\nwith cycles also enables us to handle cyclic causal tendencies and to recognize\nrecursive plans.\n","id":"http:\/\/arxiv.org\/abs\/1303.5415v1","metadata":{"abstract":"  Bayesian networks are directed acyclic graphs representing independence\nrelationships among a set of random variables. A random variable can be\nregarded as a set of exhaustive and mutually exclusive propositions. We argue\nthat there are several drawbacks resulting from the propositional nature and\nacyclic structure of Bayesian networks. To remedy these shortcomings, we\npropose a probabilistic network where nodes represent unary predicates and\nwhich may contain directed cycles. The proposed representation allows us to\nrepresent domain knowledge in a single static network even though we cannot\ndetermine the instantiations of the predicates before hand. The ability to deal\nwith cycles also enables us to handle cyclic causal tendencies and to recognize\nrecursive plans.\n","authors":["Dekang Lin"],"categories":["cs.AI"],"comment":"Appears in Proceedings of the Eighth Conference on Uncertainty in\n  Artificial Intelligence (UAI1992)","id":"http:\/\/arxiv.org\/abs\/1303.5415v1","primary_category":"cs.AI","pubdate":"2013-03-13T12:53:47Z","title":"A Probabilistic Network of Predicates"}}
{"abstract":"  Deep Learning (DL) is the most widely used tool in the contemporary field of\ncomputer vision. Its ability to accurately solve complex problems is employed\nin vision research to learn deep neural models for a variety of tasks,\nincluding security critical applications. However, it is now known that DL is\nvulnerable to adversarial attacks that can manipulate its predictions by\nintroducing visually imperceptible perturbations in images and videos. Since\nthe discovery of this phenomenon in 2013~[1], it has attracted significant\nattention of researchers from multiple sub-fields of machine intelligence. In\n[2], we reviewed the contributions made by the computer vision community in\nadversarial attacks on deep learning (and their defenses) until the advent of\nyear 2018. Many of those contributions have inspired new directions in this\narea, which has matured significantly since witnessing the first generation\nmethods. Hence, as a legacy sequel of [2], this literature review focuses on\nthe advances in this area since 2018. To ensure authenticity, we mainly\nconsider peer-reviewed contributions published in the prestigious sources of\ncomputer vision and machine learning research. Besides a comprehensive\nliterature review, the article also provides concise definitions of technical\nterminologies for non-experts in this domain. Finally, this article discusses\nchallenges and future outlook of this direction based on the literature\nreviewed herein and [2].\n","id":"http:\/\/arxiv.org\/abs\/2108.00401v2","metadata":{"abstract":"  Deep Learning (DL) is the most widely used tool in the contemporary field of\ncomputer vision. Its ability to accurately solve complex problems is employed\nin vision research to learn deep neural models for a variety of tasks,\nincluding security critical applications. However, it is now known that DL is\nvulnerable to adversarial attacks that can manipulate its predictions by\nintroducing visually imperceptible perturbations in images and videos. Since\nthe discovery of this phenomenon in 2013~[1], it has attracted significant\nattention of researchers from multiple sub-fields of machine intelligence. In\n[2], we reviewed the contributions made by the computer vision community in\nadversarial attacks on deep learning (and their defenses) until the advent of\nyear 2018. Many of those contributions have inspired new directions in this\narea, which has matured significantly since witnessing the first generation\nmethods. Hence, as a legacy sequel of [2], this literature review focuses on\nthe advances in this area since 2018. To ensure authenticity, we mainly\nconsider peer-reviewed contributions published in the prestigious sources of\ncomputer vision and machine learning research. Besides a comprehensive\nliterature review, the article also provides concise definitions of technical\nterminologies for non-experts in this domain. Finally, this article discusses\nchallenges and future outlook of this direction based on the literature\nreviewed herein and [2].\n","authors":["Naveed Akhtar","Ajmal Mian","Navid Kardan","Mubarak Shah"],"categories":["cs.CV","cs.CR","cs.CY","cs.LG"],"comment":"35 pages, 450+ references","id":"http:\/\/arxiv.org\/abs\/2108.00401v2","primary_category":"cs.CV","pubdate":"2021-08-01T08:54:47Z","title":"Advances in adversarial attacks and defenses in computer vision: A\n  survey"}}
{"abstract":"  A Bayesian network is a graphical model that encodes probabilistic\nrelationships among variables of interest. When used in conjunction with\nstatistical techniques, the graphical model has several advantages for data\nanalysis. One, because the model encodes dependencies among all variables, it\nreadily handles situations where some data entries are missing. Two, a Bayesian\nnetwork can be used to learn causal relationships, and hence can be used to\ngain understanding about a problem domain and to predict the consequences of\nintervention. Three, because the model has both a causal and probabilistic\nsemantics, it is an ideal representation for combining prior knowledge (which\noften comes in causal form) and data. Four, Bayesian statistical methods in\nconjunction with Bayesian networks offer an efficient and principled approach\nfor avoiding the overfitting of data. In this paper, we discuss methods for\nconstructing Bayesian networks from prior knowledge and summarize Bayesian\nstatistical methods for using data to improve these models. With regard to the\nlatter task, we describe methods for learning both the parameters and structure\nof a Bayesian network, including techniques for learning with incomplete data.\nIn addition, we relate Bayesian-network methods for learning to techniques for\nsupervised and unsupervised learning. We illustrate the graphical-modeling\napproach using a real-world case study.\n","id":"http:\/\/arxiv.org\/abs\/2002.00269v3","metadata":{"abstract":"  A Bayesian network is a graphical model that encodes probabilistic\nrelationships among variables of interest. When used in conjunction with\nstatistical techniques, the graphical model has several advantages for data\nanalysis. One, because the model encodes dependencies among all variables, it\nreadily handles situations where some data entries are missing. Two, a Bayesian\nnetwork can be used to learn causal relationships, and hence can be used to\ngain understanding about a problem domain and to predict the consequences of\nintervention. Three, because the model has both a causal and probabilistic\nsemantics, it is an ideal representation for combining prior knowledge (which\noften comes in causal form) and data. Four, Bayesian statistical methods in\nconjunction with Bayesian networks offer an efficient and principled approach\nfor avoiding the overfitting of data. In this paper, we discuss methods for\nconstructing Bayesian networks from prior knowledge and summarize Bayesian\nstatistical methods for using data to improve these models. With regard to the\nlatter task, we describe methods for learning both the parameters and structure\nof a Bayesian network, including techniques for learning with incomplete data.\nIn addition, we relate Bayesian-network methods for learning to techniques for\nsupervised and unsupervised learning. We illustrate the graphical-modeling\napproach using a real-world case study.\n","authors":["David Heckerman"],"categories":["cs.LG","cs.AI","stat.ML","I.2; G.3"],"comment":"Added a note on averaging causal models","id":"http:\/\/arxiv.org\/abs\/2002.00269v3","primary_category":"cs.LG","pubdate":"2020-02-01T20:03:21Z","title":"A Tutorial on Learning With Bayesian Networks"}}
{"abstract":"  Convolutional Neural Networks (CNNs) models are one of the most frequently\nused deep learning networks, and extensively used in both academia and\nindustry. Recent studies demonstrated that adversarial attacks against such\nmodels can maintain their effectiveness even when used on models other than the\none targeted by the attacker. This major property is known as transferability,\nand makes CNNs ill-suited for security applications. In this paper, we provide\nthe first comprehensive study which assesses the robustness of CNN-based models\nfor computer networks against adversarial transferability. Furthermore, we\ninvestigate whether the transferability property issue holds in computer\nnetworks applications. In our experiments, we first consider five different\nattacks: the Iterative Fast Gradient Method (I-FGSM), the Jacobian-based\nSaliency Map (JSMA), the Limited-memory Broyden Fletcher Goldfarb Shanno BFGS\n(L- BFGS), the Projected Gradient Descent (PGD), and the DeepFool attack. Then,\nwe perform these attacks against three well- known datasets: the Network-based\nDetection of IoT (N-BaIoT) dataset, the Domain Generating Algorithms (DGA)\ndataset, and the RIPE Atlas dataset. Our experimental results show clearly that\nthe transferability happens in specific use cases for the I- FGSM, the JSMA,\nand the LBFGS attack. In such scenarios, the attack success rate on the target\nnetwork range from 63.00% to 100%. Finally, we suggest two shielding strategies\nto hinder the attack transferability, by considering the Most Powerful Attacks\n(MPAs), and the mismatch LSTM architecture.\n","id":"http:\/\/arxiv.org\/abs\/2110.04488v3","metadata":{"abstract":"  Convolutional Neural Networks (CNNs) models are one of the most frequently\nused deep learning networks, and extensively used in both academia and\nindustry. Recent studies demonstrated that adversarial attacks against such\nmodels can maintain their effectiveness even when used on models other than the\none targeted by the attacker. This major property is known as transferability,\nand makes CNNs ill-suited for security applications. In this paper, we provide\nthe first comprehensive study which assesses the robustness of CNN-based models\nfor computer networks against adversarial transferability. Furthermore, we\ninvestigate whether the transferability property issue holds in computer\nnetworks applications. In our experiments, we first consider five different\nattacks: the Iterative Fast Gradient Method (I-FGSM), the Jacobian-based\nSaliency Map (JSMA), the Limited-memory Broyden Fletcher Goldfarb Shanno BFGS\n(L- BFGS), the Projected Gradient Descent (PGD), and the DeepFool attack. Then,\nwe perform these attacks against three well- known datasets: the Network-based\nDetection of IoT (N-BaIoT) dataset, the Domain Generating Algorithms (DGA)\ndataset, and the RIPE Atlas dataset. Our experimental results show clearly that\nthe transferability happens in specific use cases for the I- FGSM, the JSMA,\nand the LBFGS attack. In such scenarios, the attack success rate on the target\nnetwork range from 63.00% to 100%. Finally, we suggest two shielding strategies\nto hinder the attack transferability, by considering the Most Powerful Attacks\n(MPAs), and the mismatch LSTM architecture.\n","authors":["Ehsan Nowroozi","Yassine Mekdad","Mohammad Hajian Berenjestanaki","Mauro Conti","Abdeslam EL Fergougui"],"categories":["cs.CR","cs.AI","cs.CV","cs.LG","cs.NI"],"comment":"14 pages","id":"http:\/\/arxiv.org\/abs\/2110.04488v3","primary_category":"cs.CR","pubdate":"2021-10-09T07:20:44Z","title":"Demystifying the Transferability of Adversarial Attacks in Computer\n  Networks"}}
{"abstract":"  Artificial intelligence (AI) has become a part of everyday conversation and\nour lives. It is considered as the new electricity that is revolutionizing the\nworld. AI is heavily invested in both industry and academy. However, there is\nalso a lot of hype in the current AI debate. AI based on so-called deep\nlearning has achieved impressive results in many problems, but its limits are\nalready visible. AI has been under research since the 1940s, and the industry\nhas seen many ups and downs due to over-expectations and related\ndisappointments that have followed.\n  The purpose of this book is to give a realistic picture of AI, its history,\nits potential and limitations. We believe that AI is a helper, not a ruler of\nhumans. We begin by describing what AI is and how it has evolved over the\ndecades. After fundamentals, we explain the importance of massive data for the\ncurrent mainstream of artificial intelligence. The most common representations\nfor AI, methods, and machine learning are covered. In addition, the main\napplication areas are introduced. Computer vision has been central to the\ndevelopment of AI. The book provides a general introduction to computer vision,\nand includes an exposure to the results and applications of our own research.\nEmotions are central to human intelligence, but little use has been made in AI.\nWe present the basics of emotional intelligence and our own research on the\ntopic. We discuss super-intelligence that transcends human understanding,\nexplaining why such achievement seems impossible on the basis of present\nknowledge,and how AI could be improved. Finally, a summary is made of the\ncurrent state of AI and what to do in the future. In the appendix, we look at\nthe development of AI education, especially from the perspective of contents at\nour own university.\n","id":"http:\/\/arxiv.org\/abs\/2201.01466v1","metadata":{"abstract":"  Artificial intelligence (AI) has become a part of everyday conversation and\nour lives. It is considered as the new electricity that is revolutionizing the\nworld. AI is heavily invested in both industry and academy. However, there is\nalso a lot of hype in the current AI debate. AI based on so-called deep\nlearning has achieved impressive results in many problems, but its limits are\nalready visible. AI has been under research since the 1940s, and the industry\nhas seen many ups and downs due to over-expectations and related\ndisappointments that have followed.\n  The purpose of this book is to give a realistic picture of AI, its history,\nits potential and limitations. We believe that AI is a helper, not a ruler of\nhumans. We begin by describing what AI is and how it has evolved over the\ndecades. After fundamentals, we explain the importance of massive data for the\ncurrent mainstream of artificial intelligence. The most common representations\nfor AI, methods, and machine learning are covered. In addition, the main\napplication areas are introduced. Computer vision has been central to the\ndevelopment of AI. The book provides a general introduction to computer vision,\nand includes an exposure to the results and applications of our own research.\nEmotions are central to human intelligence, but little use has been made in AI.\nWe present the basics of emotional intelligence and our own research on the\ntopic. We discuss super-intelligence that transcends human understanding,\nexplaining why such achievement seems impossible on the basis of present\nknowledge,and how AI could be improved. Finally, a summary is made of the\ncurrent state of AI and what to do in the future. In the appendix, we look at\nthe development of AI education, especially from the perspective of contents at\nour own university.\n","authors":["Matti Pietikäinen","Olli Silven"],"categories":["cs.AI","cs.CV","cs.LG"],"comment":"234 pages. Published as an electronic publication at the University\n  of Oulu, Finland, in December 2021, ISBN: 978-952-62-3199-0 link\n  http:\/\/jultika.oulu.fi\/Record\/isbn978-952-62-3199-0","id":"http:\/\/arxiv.org\/abs\/2201.01466v1","primary_category":"cs.AI","pubdate":"2022-01-05T06:00:22Z","title":"Challenges of Artificial Intelligence -- From Machine Learning and\n  Computer Vision to Emotional Intelligence"}}
{"abstract":"  Network security has become an area of significant importance more than ever\nas highlighted by the eye-opening numbers of data breaches, attacks on critical\ninfrastructure, and malware\/ransomware\/cryptojacker attacks that are reported\nalmost every day. Increasingly, we are relying on networked infrastructure and\nwith the advent of IoT, billions of devices will be connected to the internet,\nproviding attackers with more opportunities to exploit. Traditional machine\nlearning methods have been frequently used in the context of network security.\nHowever, such methods are more based on statistical features extracted from\nsources such as binaries, emails, and packet flows.\n  On the other hand, recent years witnessed a phenomenal growth in computer\nvision mainly driven by the advances in the area of convolutional neural\nnetworks. At a glance, it is not trivial to see how computer vision methods are\nrelated to network security. Nonetheless, there is a significant amount of work\nthat highlighted how methods from computer vision can be applied in network\nsecurity for detecting attacks or building security solutions. In this paper,\nwe provide a comprehensive survey of such work under three topics; i) phishing\nattempt detection, ii) malware detection, and iii) traffic anomaly detection.\nNext, we review a set of such commercial products for which public information\nis available and explore how computer vision methods are effectively used in\nthose products. Finally, we discuss existing research gaps and future research\ndirections, especially focusing on how network security research community and\nthe industry can leverage the exponential growth of computer vision methods to\nbuild much secure networked systems.\n","id":"http:\/\/arxiv.org\/abs\/2005.03318v1","metadata":{"abstract":"  Network security has become an area of significant importance more than ever\nas highlighted by the eye-opening numbers of data breaches, attacks on critical\ninfrastructure, and malware\/ransomware\/cryptojacker attacks that are reported\nalmost every day. Increasingly, we are relying on networked infrastructure and\nwith the advent of IoT, billions of devices will be connected to the internet,\nproviding attackers with more opportunities to exploit. Traditional machine\nlearning methods have been frequently used in the context of network security.\nHowever, such methods are more based on statistical features extracted from\nsources such as binaries, emails, and packet flows.\n  On the other hand, recent years witnessed a phenomenal growth in computer\nvision mainly driven by the advances in the area of convolutional neural\nnetworks. At a glance, it is not trivial to see how computer vision methods are\nrelated to network security. Nonetheless, there is a significant amount of work\nthat highlighted how methods from computer vision can be applied in network\nsecurity for detecting attacks or building security solutions. In this paper,\nwe provide a comprehensive survey of such work under three topics; i) phishing\nattempt detection, ii) malware detection, and iii) traffic anomaly detection.\nNext, we review a set of such commercial products for which public information\nis available and explore how computer vision methods are effectively used in\nthose products. Finally, we discuss existing research gaps and future research\ndirections, especially focusing on how network security research community and\nthe industry can leverage the exponential growth of computer vision methods to\nbuild much secure networked systems.\n","authors":["Jiawei Zhao","Rahat Masood","Suranga Seneviratne"],"categories":["cs.NI","cs.CR","cs.CV"],"comment":"","id":"http:\/\/arxiv.org\/abs\/2005.03318v1","primary_category":"cs.NI","pubdate":"2020-05-07T08:29:11Z","title":"A Review of Computer Vision Methods in Network Security"}}
