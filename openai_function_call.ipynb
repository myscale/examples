{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')\n",
    "os.environ['MYSCALE_HOST'] = getpass.getpass('MyScale URL:')\n",
    "os.environ['MYSCALE_PORT'] = getpass.getpass('MyScale Port:')\n",
    "os.environ['MYSCALE_USERNAME'] = getpass.getpass('MyScale Username:')\n",
    "os.environ['MYSCALE_PASSWORD'] = getpass.getpass('MyScale Password:')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a MyScale vectorstore and insert data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting data...: 100%|██████████| 8/8 [00:01<00:00,  4.41it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import MyScale\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def str2doc(_str):\n",
    "    j = json.loads(_str)\n",
    "    return Document(page_content=j['abstract'], metadata=j['metadata'])\n",
    "\n",
    "with open('func_call_data.jsonl') as f:\n",
    "    docs = [str2doc(l) for l in f.readlines()]\n",
    "\n",
    "vectorstore = MyScale.from_documents(documents=docs, embedding=HuggingFaceEmbeddings())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define metedata columns\n",
    "\n",
    "We used `AttributeInfo` from [LangChain](https://python.langchain.com/en/latest/), and format metadata into strings. That data will be later used as prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{\n",
      "    \"metadata.pubdate\": {{\n",
      "        \"description\": \"The date when paper is published, need to use `parseDateTime32BestEffort() to convert timestamps in string format to comparable format.` \",\n",
      "        \"type\": \"timestamp\"\n",
      "    }},\n",
      "    \"metadata.authors\": {{\n",
      "        \"description\": \"List of author names\",\n",
      "        \"type\": \"list[string]\"\n",
      "    }},\n",
      "    \"metadata.title\": {{\n",
      "        \"description\": \"Title of the paper\",\n",
      "        \"type\": \"string\"\n",
      "    }},\n",
      "    \"text\": {{\n",
      "        \"description\": \"Abstract of the paper\",\n",
      "        \"type\": \"string\"\n",
      "    }},\n",
      "    \"metadata.categories\": {{\n",
      "        \"description\": \"arxiv categories to this paper\",\n",
      "        \"type\": \"list[string]\"\n",
      "    }},\n",
      "    \"length(metadata.categories)\": {{\n",
      "        \"description\": \"length of arxiv categories to this paper\",\n",
      "        \"type\": \"int\"\n",
      "    }}\n",
      "}}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.query_constructor.base import _format_attribute_info, AttributeInfo\n",
    "\n",
    "metadata_field_info=[\n",
    "    AttributeInfo(\n",
    "        name=\"metadata.pubdate\",\n",
    "        description=\"The date when paper is published, need to use `parseDateTime32BestEffort() to convert timestamps in string format to comparable format.` \", \n",
    "        type=\"timestamp\", \n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"metadata.authors\",\n",
    "        description=\"List of author names\", \n",
    "        type=\"list[string]\", \n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"metadata.title\",\n",
    "        description=\"Title of the paper\", \n",
    "        type=\"string\", \n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"text\",\n",
    "        description=\"Abstract of the paper\", \n",
    "        type=\"string\", \n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"metadata.categories\",\n",
    "        description=\"arxiv categories to this paper\",\n",
    "        type=\"list[string]\"\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"length(metadata.categories)\",\n",
    "        description=\"length of arxiv categories to this paper\",\n",
    "        type=\"int\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "formated = _format_attribute_info(metadata_field_info)\n",
    "print(formated)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ... And here is the magic! Function Call from OpenAI\n",
    "\n",
    "Still, prompting is important. We inject metadata and some instruction with conversation context.\n",
    "\n",
    "We used the plain text way to call with openai, following the [official documentation](https://platform.openai.com/docs/guides/gpt/function-calling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is a Bayesian network?', 'where_str': \"parseDateTime32BestEffort(metadata.pubdate) > parseDateTime32BestEffort('2013-02-01') AND text LIKE '%artificial%' AND length(metadata.categories) > 2 AND has(metadata.categories, 'cs.CV')\", 'limit': 10}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "query = \"What is a Bayesian network? Please use articles published later than Feb 2013 and whose abstract like `artificial` with more than 2 categories and must have `cs.CV` in its category.\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        temperature=0,\n",
    "        functions=[{\"name\": \"to_structued_sql\", \n",
    "                    \"description\": \"Convert the query into a query string and a where string to filter this query. When checking if elements is in a list, please use `has(column, element)`\",\n",
    "                    \"parameters\": {\"type\": \"object\", \n",
    "                                   \"properties\": {\"query\": {\"type\": \"string\"},\n",
    "                                                  \"where_str\": {\"type\": \"string\",},\n",
    "                                                  \"limit\": {\"type\": \"integer\", \"description\": \"default to 4\"}},\n",
    "                                   \"required\": [\"subject\", \"where_str\", \"limit\"]\n",
    "                                   }\n",
    "                    },],\n",
    "        function_call=\"auto\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You need to provide `metadata` to construct SQL. I will use `parseDateTime32BestEffort()` to convert timestamps in string format to comparable format.\",\n",
    "            },\n",
    "            {\n",
    "                 \"role\": \"user\",\n",
    "                \"content\": f\"Metadata: {formated}\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Now you can input your query\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "import json\n",
    "search_kwargs = json.loads(completion.choices[0].message.function_call.arguments)\n",
    "print(search_kwargs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then search!\n",
    "\n",
    "This is the exact same compared to LangChain self-query retrievers. And it is more flexible - it can write any SQL... and even user defined functions. \n",
    "\n",
    "It is up to you to redefine how databases with vector search interact with AGI systems!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "page_content='  Artificial intelligence (AI) has become a part of everyday conversation and\\nour lives. It is considered as the new electricity that is revolutionizing the\\nworld. AI is heavily invested in both industry and academy. However, there is\\nalso a lot of hype in the current AI debate. AI based on so-called deep\\nlearning has achieved impressive results in many problems, but its limits are\\nalready visible. AI has been under research since the 1940s, and the industry\\nhas seen many ups and downs due to over-expectations and related\\ndisappointments that have followed.\\n  The purpose of this book is to give a realistic picture of AI, its history,\\nits potential and limitations. We believe that AI is a helper, not a ruler of\\nhumans. We begin by describing what AI is and how it has evolved over the\\ndecades. After fundamentals, we explain the importance of massive data for the\\ncurrent mainstream of artificial intelligence. The most common representations\\nfor AI, methods, and machine learning are covered. In addition, the main\\napplication areas are introduced. Computer vision has been central to the\\ndevelopment of AI. The book provides a general introduction to computer vision,\\nand includes an exposure to the results and applications of our own research.\\nEmotions are central to human intelligence, but little use has been made in AI.\\nWe present the basics of emotional intelligence and our own research on the\\ntopic. We discuss super-intelligence that transcends human understanding,\\nexplaining why such achievement seems impossible on the basis of present\\nknowledge,and how AI could be improved. Finally, a summary is made of the\\ncurrent state of AI and what to do in the future. In the appendix, we look at\\nthe development of AI education, especially from the perspective of contents at\\nour own university.\\n' metadata={'abstract': '  Artificial intelligence (AI) has become a part of everyday conversation and\\nour lives. It is considered as the new electricity that is revolutionizing the\\nworld. AI is heavily invested in both industry and academy. However, there is\\nalso a lot of hype in the current AI debate. AI based on so-called deep\\nlearning has achieved impressive results in many problems, but its limits are\\nalready visible. AI has been under research since the 1940s, and the industry\\nhas seen many ups and downs due to over-expectations and related\\ndisappointments that have followed.\\n  The purpose of this book is to give a realistic picture of AI, its history,\\nits potential and limitations. We believe that AI is a helper, not a ruler of\\nhumans. We begin by describing what AI is and how it has evolved over the\\ndecades. After fundamentals, we explain the importance of massive data for the\\ncurrent mainstream of artificial intelligence. The most common representations\\nfor AI, methods, and machine learning are covered. In addition, the main\\napplication areas are introduced. Computer vision has been central to the\\ndevelopment of AI. The book provides a general introduction to computer vision,\\nand includes an exposure to the results and applications of our own research.\\nEmotions are central to human intelligence, but little use has been made in AI.\\nWe present the basics of emotional intelligence and our own research on the\\ntopic. We discuss super-intelligence that transcends human understanding,\\nexplaining why such achievement seems impossible on the basis of present\\nknowledge,and how AI could be improved. Finally, a summary is made of the\\ncurrent state of AI and what to do in the future. In the appendix, we look at\\nthe development of AI education, especially from the perspective of contents at\\nour own university.\\n', 'authors': ['Matti Pietikäinen', 'Olli Silven'], 'categories': ['cs.AI', 'cs.CV', 'cs.LG'], 'comment': '234 pages. Published as an electronic publication at the University\\n  of Oulu, Finland, in December 2021, ISBN: 978-952-62-3199-0 link\\n  http://jultika.oulu.fi/Record/isbn978-952-62-3199-0', 'id': 'http://arxiv.org/abs/2201.01466v1', 'primary_category': 'cs.AI', 'pubdate': '2022-01-05T06:00:22Z', 'title': 'Challenges of Artificial Intelligence -- From Machine Learning and\\n  Computer Vision to Emotional Intelligence'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ret = vectorstore.similarity_search(**search_kwargs)\n",
    "print(len(ret))\n",
    "for r in ret:\n",
    "    print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
